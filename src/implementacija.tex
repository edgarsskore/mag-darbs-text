\chapter{Plūsmas analīzes algoritma implementācija}
Plūsmas analīzes algoritma implementācija tika veidota programmēšanas valodā \textit{Python}, izmantojot \textit{caffe}. Šis ietvars tika izmantots, lai veiktu \textit{VGG Net} konvolūcijas neironu tīkla modelēšanu un apmācību objektu klasificēšanai un implementētu \textit{SSD} algoritmu objektu detektēšanai. Lai gan gala risinājums tika veidots izmantojot \textit{SSD} algoritmu, lai rastu plašāku ieskatu pieejamajos risinājumus, tika apskatīts arī \textit{YOLO} objektu detektēšanas algoritms, kas implementēts \textit{darknet} ietvarā.

Neatkarīgi no objektu detektēšanas algoritma un ietvara, kurā tas implementēts, gala risinājums sastāv no četrām daļām: datu kopas sagatavošanas, konvolūcijas neironu tīkla apmācības, objektu detektēšanas algoritma implementācijas un sekošanas algoritma implementācijas. Pēc datu sagatavošanas, tiek veikta konvolūcijas neironu tīkla apmācība,  lai tas būtu spējīgs klasificēt attēlos vai video fragmentos esošos objektus. Kad apmācīts pietiekami precīzs modelis, to katrā kadrā izmanto objektu detektēšanas algoritms, lai meklētu objektus. Kad objekts atrasts, tā vietā tiek inicializēts sekošanas algoritms, kas nākamajos kadros noteiks objekta atrašanās vietu, ja to vairs nebūs iespējams detektēt. 
\section{Cilvēku galvas noteikšanas datu sagatavošana}
Lai veiksmīgi apmācītu konvolūcijas neironu tīklus objektu detektēšanai, ir nepieciešama liela datu kopa ar meklējamo objektu piemēriem, šajā gadījumā ar cilvēku galvu attēliem. Jo vairāk datu, jo dažādākus objektus apmācītais tīkls spēs klasificēt. Šī darba nolūkos interesējošie piemēri ir cilvēku galvu attēli un ir pieejamas vairākas datu kopas, autors šī darba nolūkos ir izvēlējies \textit{HollywoodHeads} datu kopu \cite{vu15heads}. 

\textit{HollywoodHeads} datu kopa satur 369 846 cilvēku galvu anotācijas (anotācija ir \textit{XML} formāta fails, kas piekārtots katram datu kopas attēlam un satur informāciju par attēlu, par objektu, kādi objekti redzami attēlā un šo objektu ierobežojošie logi), 224 740 video kadros no 21 Holivudas filmām\footnote{Filmu saraksts: American beauty, As Good As It Gets, Big Fish, Big Lebowski, Bringing out the
dead, Capote, Clerks, Crash, Dead Poets Society, Double Indemnity, Erin
Brockovich, Fantastic 4, Fargo, Fear And Loathing In Las Vegas, Fight	Club,Five Easy Pieces, Forrest Gump, Gang Related, Gandhi, Charade, I Am Sam}. Šīs filmas ir no dažādiem žanriem un laika brīžiem vēsturē, lai piedāvātu visdažādākos galvu piemērus. Lai izveidotu anotācijas, datu kopas veidotāji manuāli atlasīja cilvēku galvas no rīcības bagātām ainām. Katrai galvai manuāli tika izveidoti ierobežojošie logi (mazākais iespējamais laukums, kurā ietilpst visi galvas redzamie pikseļi), vairāku kadru garumā. Kopā tika savākti dati no 2 380 klipiem ar 3 872 apsekotiem cilvēkiem, kas kopā veido vairāk kā 3.5 stundas ar video fragmentiem. Datu kopa ir sadalīta apmācības, validācijas un testēšanas apakškopās un šīs apakškopas, filmu ziņā, nepārklājas. \textit{HollywoodHeads} apmācības datu apakškopa satur 216 719 kadrus no 15 filmām, validācijas apakškopa satur 6 719 kadrus no 3 filmām un testēšanas apakškopa satur 1 302 kadrus no 3 filmām. Cilvēku galvas, kurām priekšā ir šķēršļi vai ir slikts apgaismojums ir anotācijās apzīmētas kā "sarežģīti" (no angļu val. \textit{difficult}) piemēri un netiek izmantoti apmācības laikā. 

Diemžēl, izvēlēto datu kopu gan nav iespējams uzreiz pielietot apmācībā, jo formāts kādā strukturēti dati vienmēr nav saderīgs ar formātu kādu sagaida ietvars, šajā gadījumā \textit{caffe} un \textit{darknet}. Konvolūciju neironu tīklu apmācībā populāras datu kopas ir: \textit{COCO} \cite{lin2014microsoft}, \textit{PASCAL VOC} \cite{everingham2010pascal} un \textit{ILSVRC} \cite{ILSVRC15}. \textit{Caffe} un \textit{darknet} ietvaros ir iebūvēta iespēja apmācīt CNN ar visām minētajām datu kopām, izņemot \textit{HollywoodHeads} datu kopu. Šīs problēmas risinājums gan nav sarežģīts. Autors aizstāja \textit{VOC} datu kopas attēlus un anotācijas (anotāciju struktūra abām datu kopām sakrīt un specifiski anotāciju pārveidojumi nav nepieciešami) ar \textit{HollywoodHeads} datu kopas attēliem un anotācijām un gan \textit{caffe}, gan \textit{darknet} uzstādījumos bija nepieciešams nomainīt klašu skaitu. \textit{Caffe} gadījumā klašu skaits no 20 (\textit{VOC} gadījumā) tika samainīts uz 2 klasēm (galva un fons), kamēr \textit{darknet} gadījumā klašu skaits no 20 tika samainīts uz 1 klasi (galva).

Nākamais solis datu sagatavošanā \textit{caffe} ietvaram ir izveidot \textit{LMDB} (\textit{Lightning Memory-Mapped Database}), kurā iekodēs attēlu informāciju. \textit{LMDB} ir ļoti augstas veiktspējas, kompakta datu glabātuve, kas izmanto atmiņā kartētus failus, lai varētu lasīt datus ar augstu veiktspēju, tai pašā laikā saglabājot standarta uz diskiem balstīto datu glabātuvju ietilpību. Apmācības, validācijas un testēšanas datu apakškopām katrai būs sava \textit{LMDB} datu glabātuve ar saitēm uz pašu datu kopu. \textit{Bash} skripts, kas izveidos šīs datubāzes ir ievietots pielikumā \ref{appendix:pielikums1}.

\textit{Darknet} ietvara gadījumā, no \textit{VOC} formāta datiem ir nepieciešams izveidot marķējumu (no angļu val. \textit{label}) failus, kas no anotāciju failiem iegūs attēlos esošo objektu ierobežojošo logu izmērus un atrašanās vietas un klasi kurām pieder šie logi. Marķējumu faili katrā rindā satur informāciju par vienu no ierobežojošajiem logiem, formātā :\\ $<objekta-klase> <x> <y> <platums> <augstums>$.\\
Kur \textit{x,y, platums, augstums} ir atkarīgi no attēla platuma un augstuma. Lai automātiski izveidotu marķējumu failus katram attēlam, ir nepieciešams palaist \textit{Python} programmēšanas valodā rakstītu skriptu, kas pievienots pielikumā \ref{appendix:pielikums2}. Šis skripts nolasa katru anotācijas failu un atkarībā no anotācijas failā atrastajiem parametriem, katram attēlam izveido marķējumu failu ar iepriekš minēto informāciju.
\section{Konvolūcijas neironu tīkla apmācība}
\section{Sekošanas algoritmu implementācija}